
20160315
我回顾了一下上次提交的中期报告，确实缺少一个能够贯穿全文的思路（研究目的）。我又整理了一下上学期所有的一些想法，觉得可以概括如下：

    计算机句法分析时会分词：对于“喜极而泣”，会处理成“ 喜极而泣 / l ”（但实际上用NLPIR分词得到的是“ 喜/v 极/d 而/cc 泣/vg ”），而对于“悲极而泣”，“怒极而泣”，则可能分析为 “ 悲/ag 极/ng 而/cc 泣/vg ”。
    这样的分词结果显然是不符合预期的：我们并没有感觉到“悲极而泣”是四个支离破碎的单位，而是一个完整的单位。
    那么问题来了：
    1. “悲极而泣”是不是一个词（假设“喜极而泣”是一个词）？
      答：是
    2. 既然是一个词，那该不该收进词库？
      答：不该——除非它的频率已经足够高了，在人脑中十分凝固了。否则人们在看到这个词时，一定会 联想到/激活 它的基式（“喜极而泣”），也就是说它不是一个具有独立形式和意义的词，而是另一个词的临时派生形式。而且这样的派生有很多。
    3. 既然不收进词库，那遇到这样的词怎么办？
      【研究目的】答：研究清楚这类词的派生规律，并用这些规律帮助识别它们。换言之，分词的时候不仅仅依赖词表匹配，还借助于派生规律。
    4. 有哪些派生规律？
      【研究方法】答：1. 替换（主要体现在单槽模式）；2. 对举（双槽模式）；3. 紧缩（三槽模式）。随着槽数增加，基式作用越来越小。
    5. 构式在其中起了什么作用？
      【研究手段】答：指导作用。构式方法在此弥补了短语文法在构词上的不足。

    基于使用的观点比基于规则的观点更具体，更具有覆盖力。规则的观点倾向于二分：是规则就是规则，不是规则就不是规则，规则一旦建立，就好像可以脱离实例而存在。它对于像“人怂志短”这样似是而非的规则的处理能力是比较弱的。而基于使用的观点则强调实例的作用，注重规则形成的过程：尽管“人…志短”只有两个实例，但我不否认它的存在。
    FCG的观点则认为重点不在于规则有多完备（即构式库有多少构式），而是规则不完备时如何补救（repair），这个补救其实就是“规则的规则”，我们在文中就通过对细胞词库的分析找到了几种补救规则（主要是替换、对举，紧缩已经没法“有效补救”了）。
    整篇文章的逻辑还是如最开始设计的那样，先通过词库“人工训练”出规则集，再将规则集应用到语料库中——具体说，是语料库中被分词程序切分成支离破碎的连续单字词的片段上。我们试图从这些片段中找出一些更完整的东西。与开始设想得不一致的地方是，开始我们希望找到的是具体的规则集（即构式），而现在我们更倾向于找到规则的规则。很多的构式其实能产性都不强，例如“X眉Y目”，“心X手Y”，因为常项是名词，限制了其派生能力；但这类“对举交替双槽模式”的数量很庞大，对举构式的能产性很强。

    关于讨论班报告，我其实倾向于读一些理论性质的文章，而不是应用性质的文章。前者其实更难读，但读完后可能收获更大一些。我也十分乐意去读一些应用性质的文章，比如可以分别挑几篇待嵌格式、四字格、网络新词的文章来读，综述并评述。这样应该也是不错的读书报告。

20160229
论文原初打算分两部分：词库部分，也就是通过聚类把构式找出来；语料库部分，也就是通过语料来衡量找出的构式的“强度”，或称为构式感。但是现在打算把方向改一改：重点放在词库上。
    聚类算法不难写，在开题的时候其实已经写好并将聚类结果展示出来了，但我在接下来的研究中钻了一下牛角尖：我很好奇也很反感，为什么所有的四字词库组合到一起会产生9万多条记录，且中间有大部分是“噪音”，也就是根本不该收进来的四字组合（这些组合有些词义很弱，有些根本就不是词，而是一个短语的一部分）。于是我做了很多额外的统计，最开始的希望是尽量把那些根本不该收进来的四字组合剔出去，留下来一个像模像样的词表，然后再在这个词表上进行聚类，得到一个满意的构式集。——其实如果一开始就去重点、逐条分析那些高频的“二字交替显现、二字交替隐含”的构式，说不定能按照原计划进行下去，虽然结果可能比较粗糙。
    在这些额外的统计、分析和思考中，看到了一些很有意思的、很实际的问题。比如“简繁转换”，我费了一番功夫，弄明白了为啥会有“説”和“說”两个汉字。在这个过程中，我逐渐发现，要界定一个未登录的四字组合是不是词，成语感强不强，本身就是一件困难的事儿，也是一件有意义的事儿。——我现在有一个想法，断定一个未登录的四字组合是词，只有两种情况：要么它（某一时期）的频率特别高，要么它与已有的某一个（类）词发生了某种联系。第一种我称之为创造，第二种我称之为推理。创造的词不是我关注的重点，它频率的特点已经很突出了。我关心的是推理得来的词，它之所以能被推理得来，正因为构式在起作用。
    所以我现在想做的一件事情，就是借助构式的手段，去分析一个新结构到底该不该被收进词库中。结果大致是这样：如果一个结构不符合上述两种情况，那就根本不该收进词库；如果它频率很高且并没有明显由某一构式实例化而来的迹象，那就应该被收进词库；如果它像是从某一构式实例化而来，那么我们得分析，它到底是不是“误写”，比如，是不是写错字了。如果不是误写，那么可以收进词库，更准确地，可以收进个人词库，然后决定要不要进一步收进系统词库。——构式在其中起指导性的作用，我们首先要用构式的方法将这个9万多词的大词库“瘦瘦身”，然后给出今后遇到新词的解决办法。我的新题目是《构式指导下的现代汉语四字词库的规模控制》，其意义不仅是判断一个新的四字结构是不是“词”，更给出了一个工程上收录词的标准，避免把一些显然不是词的片段或者是误写的词被收入词库。
    而可以发现，以上的思路跟FCG的思想是一致的。我目前读到并理解的FCG的核心思想并不是“如何用已有的构式库去分析语言结构”，而是“如何在构式库不够用的时候仍能正常工作”（来了一个新词，发生Repair，要么改正该词，要么收录该词，要么舍弃该词）。我希望再回味一遍FCG的目的并不是说我要真的借用FCG的程序去分析，而是我希望用他们的观点来加强我的论述。另外还有一个我认为很深刻的思想就是Preemption，这个已经比较清楚地报告过了。——我的论文其实最终的目的并不是提出一个精简词库的方法，而是论述一个词是怎么来的。最终是想解释，什么是构式。
    我在下周五的报告中会具体地展开一些问题。

