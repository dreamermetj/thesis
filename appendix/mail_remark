20160331
各位好，

    今天继续进行一些头脑风暴，主要考虑的问题是，其实提到的几个能产性恰能用来判别四字格“是词不是语”的特质，分析如下：

    四字格跟普通词的最大的区别在于：普通词是一个语言形式到一个基元实体/状态/……（atomic entity/state...）的映射，但四字格的映射关系就没有那么明确。如果把映射等价于语言学中与形式相匹配的意义，那么可以说，四字格本身似乎并没有带上什么意义，四字格的意义完全可以由字义和字的组合义来描述——有人就说了，组合义难道不就是格式义吗？如果是这样，那么，比喻、夸张等修辞手段全部都可以看做所谓的格式义，但实际上，比喻、夸张并没有固定的格式；另一方面，就算有，我们一般也把这种格式看成是语法格式，而不是语汇格式。
    四字格有以下这些特质，这些特质决定了四字格应该归为词，而非短语，要注明的是，并不是每一个四字格都拥有所有的特质。
    1. 四字格确乎是一个基元。它的内部发生一些微小的变化：顺序颠倒，或者写错一个字甚至两个字，都不影响整体意义的理解。是谓误写能产性；
    2. 四字格能引喻，但引喻之后的新形式必须依附于原有形式，这跟短语是有区别的。是谓引喻能产性；
    3. 此外，四字格还十分紧凑，其中多数单字拆开来并不成词，是谓紧缩能产性；
    4. 很多四字格中，间隔的字可能是重复或者意义上重复的，这也是一般短语不出现的“复沓”，是谓对举能产性。
    几点说明：
    1. 虽然误写能产性产出的并不都是有意义的四字格，但在真实语料中，确实不乏这样的实例，就算当作研究自动纠错，也应该考察这一类实例。
    2. 误写能产性与引喻能产性是有重合的，比如“谈古论今”，不小心打成了“谈股论今”，有人一下子发现了欸这不是在形容股票于今日的地位吗，还有啥“谈股色变”都很类似啊，所以由误写变成了引喻。再引喻一下，变成了“谈股论金”，从字面上完全与原四字格没有关系了，但它还是从“谈古论今”引喻过来的，而不是从“谈X论Y”对举过来的。原因很简单：没有“谈古论今”，就不可能有“谈股论金”；不知道前者，就无法体会后者的妙处。
    3. 像“一v而X”这样的双槽模式都属于紧缩能产性。紧缩能产性的特点就是没有什么特殊的意义，它能做的就是把一个语法形式压缩成一个语汇形式。甚至“千X万Y”也偏向紧缩能产性。有人觉得“一v而X”的构式义是“表迅速、果断”，觉得“千X万Y”是形容数量多。我的感觉是这俩意义都是由字或结构带来的（“一”和“千、万”），不能把字和常规结构上的意义带到构式上——除非你认为“一……就……”这个常见的连锁结构就是构式。紧缩能产性最大的特点是形式紧缩，不要过度解读意义上的各异。

20160330(2)

恩，我先试图把思路和文章结构再理清楚一些。

所谓能产性，是基于这样一个事实：“我们对四字词并不陌生，但现实生活、真实语料中出现的四字词数量可能会超乎我们的预估。”

对NLP的挑战表现为：现有的基于分词的NLP任务，在分词环节就会因词典中四字词语的缺失而导致错误。而且这些四字词语，几乎没办法用简单的统计的方法（比如顾森的程序）甄选出来，因为它们绝对低频。

词典收不收这些所有的四字词语？不收。收不完，一般也用不着（频率实在太低）。

那怎么办？我们提出一些方法，不敢说全部把四字词语找出来，但至少能找出一部分四字词语——在分词前做一个预识别、或者在分词后把几个词素合并为一个四字词，就能提高分词的准确性。

这些方法是啥？主要是对举识别和引喻识别，（三槽模式如“XX之X”的识别呢，我再努力努力，但估计很难搞出像样的有规模的成果）。

方法的准确度怎么样？抱歉，这里是弱点，我们没有办法准确地统计出识别率，这毕竟涉及到人工一条一条的检查，工作量太大，但我们能给你一个大概的预期，告诉你这些方法是work的，且确实能找出一大批“不应该收入词典的四字词”。至于你今后怎么做改进，那是后话。我们的目的在于提出这样的可操作的方法，这是本文的重点。所以我们的标题是否应该改为“新词发现”？

此外，为了加强对举识别和引喻识别的说服力，我们还打算涉及两块区域：一是那么多搜狗细胞词库是有层次的，大词库包含着小词库，小词库我们假设是比较核心的，那么随着词库的扩大，新加进来的词是不是就可以看做新词呢？它们中有多大比例是通过对举和引喻产生的呢？

二才是理论讨论部分。也就是说之前那几封邮件讨论的种种理论，其实都是我为论文倒数第二章打的一些草稿，某种程度上故意偏激一些以引发大家的讨论。我的这些理论呢，主要是为“对举”和“引喻”正名的，至于“有没有规则的概念”，如果确实容易引起误会（估计也不会引起太多的关注，毕竟是最后不怎么好吃的“鱼尾”了），那我们可以不谈，它对“对举”和“引喻”也没啥必要的贡献。

那么基于这三块内容（语料中的新词发现、词典中的扩展研究、理论探讨），我觉得用“能产性”要比“新词发现”更好一些，因为毕竟，我的最终目的是要说明这种词语的产生途径的。这里的能产性并不是针对具体的构式进行比较的（比如证明“一无所X”的能产性比“无所不X”高，这也是没有意义的），这种能产性是面对整个四字词语而言的，“汉语四字词在以至少两条途径快速地扩张着”。

然后和最后，我稍微再解释一下“没有语法规则”的说法。其实我做了很多遍铺陈，我的重点是“不要避开实例空谈规则”，为什么呢？因为规则来源于实例，规则是实例的概括，大方向的概括一般没啥问题，但在小方向上规则很容易以偏概全造成错误，变得“为了达到语言的一致性而一致”。实例集跟规则应该是等价的，规则说有就有，说无也可以无，但实例是肯定存在的。实例在客观性上要高于规则。因此我们为什么非要去证明“一无所X”的存在性呢？这不重要啊，重要的是我们知道有“一无所有”“一无所知”这些实例，这就够了。非要规则第一位，那好了，“千叠万壑”是来源于“千X万Y”的吗？所以真正影响你遣词造句的，咱不说“很少是规则”，至少“不全是所谓的规则”吧？我想说的，就是通过引喻的或对举的“规则”，要比我们一般认识中的纯框架式的规则的能产性高得多。因为前者才是符合认知的。概括永远解释不了能产，前人概括了一辈子“被+vt”，甚至还概括出了长被句和短被句，最后却被“被+vi”搞蒙了。

20160330
今天我就“一无所有”的问题又想了想，感觉这么讲是能讲通的：我们首先要保证我们找到的四字结构确实是一个完整的结构（无论是词还是词组），接下来，才能进行统计（标红的是伪实例，要排除的）：

    X(A) = {一（892）、空（98）、别（13）、豪（7）、见（4）、物（2）、……}
    X(B) = {无(892)、切(69)、个(57)、方(42)、种(39)、是(36)、……}
    X(C) = {所(892)、两(17)、三(1)}
    X(D) = {知(1397)、有（892）、获（639）、得（87）、成（49）、求（36）、长（25）、见（23）、……}

    然后，我们的感觉是：“一无所有”是来自于“一无所X”，而非“X无所有”、“一X所有”、“一无X有”的。更进一步，根本就没有后面三种构式，它们“生成”的实例根本不是来自于它们本身的。

    这个感觉是对的，并且可以用数字衡量：根据词的定义（顾森的热词发现也是这么做的），词不仅要内部凝固，还要外部自由，换言之，词的外部环境的混乱度（熵）应该比较高才对，否则如“啄木”，虽然内部很凝固，但它的右边大概率出现“鸟”，所以“啄木”并不是一个词，“啄木鸟”才是。
    显然，entropy(X(D)) >> entropy(X(A)) ~ entropy(X(B)) ~ entropy(X(C))
    所以X(D)才有可能是一个构式，而X(A)、X(B)、X(C)都不是构式。

    但这个度量也有不足，就是它只衡量了一半的混乱度。对于“S1 一X所有 S2”而言，“一…所有”的外部环境不仅有X，还有S1和S2。而对于“S1 一无所X”而言，它除了需要度量S1外，还需要证明“一无所X”是一个结构。否则，就如“更进一步”的例子， X(A) = {要、将、的、为、了、于、在、到、会、就、以、作、是、望、系、能、国、应}，虽然entropy(X(A))很大，但它充其量只能说明“进一步”是一个构式。

    这个度量的另一个（对本次论文而言）更大的不足是：它对于“能产性”的贡献是很小的，因为它充其量只能说明我们脑海里有一个构式“一无所X”，至于我们用不用它、怎么用它，这个度量解决不了。这其实就是基于使用的方法的一个重要的地方，FCG明确地提了出来，就是构式是有个排序的（preemption其实也是这个思想）。结构语法的疏忽在于生产，假设现在“把”字句和“被”字句都能描述一件事情，我们怎么选择？结构语法应该是默认它们是等可能事件。但很多认知的术语（prime, preempt, ...）恰恰在于否定这一点。这就是我说的“规则一旦脱离实例独自存在就容易‘为了解决问题而解决问题’”。我的强烈的看法是，人的脑海里是没有语法规则的（第二语言习得者除外，词语到实体间的映射除外），人们有的是海量的实例，各种参差不齐的句子。它们是人们组织语言的依据。当然，我们可以根据海量的实例去抽象出规则，比如最基本的SVO语序，这基本可以看作是一种认知模式了，用着没什么问题。但在细处，一个规则的认知意义不那么强烈的时候，再去过度依赖规则就容易出问题了。

    所以，我的看法是尽量避免过分强调构式的存现性，去分析一个构式到底存不存在，甚至去给这个构式分析出五花八门的意义。这些意义一说出来争议都是很大的。像双及物构式（正常下一个动词只带一个宾语）、被+vi（正常下不及物动词没有宾语）、不是X的X（正常下X就是X）这些明显由语法或语义矛盾带来意义的构式是很少的，更多的情况下构式是人们的一种使用的倾向。而像什么“东X西Y”、“V来V去”，分析出五六种语义结构的，我真的不能接受。

    所以我重点想说，人们有哪些使用倾向。这其中有些东西是与直觉相悖的，比如entropy(“千X万Y”)一定远大于entropy(“千X万壑”）（假如能发明出把单槽和双槽统一到一个维度上的算法），但为什么我说“千叠万壑”更像是来源于单槽呢？就是因为假如你脑海里没有“千山万壑”这个词，你是很难凭“千山万水”“千紫万红”等经验创造出“千叠万壑”的，你可能会说出“千重万叠”或者“千峰万壑”（创造出这些其实也很困难，因为“峰”和“壑”都不是一个现代汉语的词，你要把“山峰”和“沟壑”压缩成“峰”和“壑”，这是很复杂的），但你更可能说出“峰峦叠嶂”或干脆“好多山好多谷”等等你熟悉的表达。

    我今天还做了一件事儿，就是把从词库中抽取构式的结果变得更好了，至少跟原来的结果比好的不是一点半点。怎么做的报告时再讨论。现在先对比一下（更改后 v.s. 更改前）：

    我现在的想法是，我会把这些结果贴出来，不过我并不是要强调“进退XX”出现了47次，能产性很高，我要强调的是，这种“一二对举模式”的能产性很高，无论是反义如“进退两难”、“表里如一”还是近义如“风雨无阻”、“富贵齐天”；我要强调的是“不可XX”“不知XX”其实是“不+v+XX”的半实例化（这个相对比较牵强）……等等。
20160328(4)
总之，我并不是一味地倾向“经验主义”或者“机器学习”，现在的机器学习方法其实也是经过一系列简化，把一个多维的、多层次的问题压缩到一个平面上，（或者把一个线性不可分的问题转换到高维空间上变得可分），它跟结构主义语言学的问题其实是一样的，就是总是希望通过制造某种有序来解决一个看似无序的问题。而我希望做的无非是强调一下“不要为了解决问题而解决问题”，说明一下“解决问题要回到本质上”，说明一下“问题的本质是：一个新表达是怎么来的，而不是说现有的表达能够分成多少类”，如果后者能对前者起决定作用，那么研究后者当然是好的，但问题就是现在看来后者并没有这么大的作用。所以，我希望的是重点描述一下我发明的“对举能产性”、“引喻能产性”和“紧缩能产性”，这些现象其实前人都描述过（比如文炼《固定短语和类固定短语》），只不过前人并不很看重它们，只不过把它们当作一种特殊的现象简单交代。我想用更多的数据来加强“这些能产性在四字结构的生产上很重要”这个观点——能够做到量化当然更好，做不到的话，至少方向上我更希望把理念描述清楚。
20160328(3)
非要说这么多实例type都是越过“千X万壑”直接从“千X万Y”派生的，并不是很令人信服。但是。说“千X万壑”是个构式，也不很令人舒服。怎么办呢？我们认为，这些实例的派生途径是“引喻”而不是“对举”。甚至很多人根本就不明白“壑”具体指什么。总之呢，他们知道“千山万壑”、“千岩万壑”，感觉这就是形容山峦叠嶂的，于是他们借这个词，来突出某一个他们所见之物，比如“林”（跟“壑”对举不强）；或者就杂糅进去一个“叠”。既然是引喻，那就更倾向于认为它们从“千X万壑”而来，至于是不是呢？不重要，也说不清楚。重要的是，我们知道了四字词衍化的途径有引喻和对举，我们发现了前人没有注意过的边缘低频词汇，我们在论述跟前人不一样的能产性。我们甚至希望进一步说明，引喻能产性比对举能产性要高，因为前者的焦点只有一个，剩下的都是已知的、相对完整的背景知识，即利于生产，也便于理解。

    如果大家对以上看法有异议，欢迎提出，或在讨论班上讨论（要尽早。。。）
    当然，对于量化分析这块短板，也欢迎大家继续提出建议。詹老师说的那个方案，我现在确实感觉有点难于下手，也请詹老师再指导

20160328(2)
定量的估计目前还没有做，我下一周会想想办法弄出一个数据来。
    定量分析是我一开始致力于做的一件事，后来发现要有质量地完成这件事，特别是整体地对四字结构进行一个定量的描述，是很困难的，很容易走上歧路。所以我这篇文章的主要论述都还是定性的，定量只起一种补充性的、增强性的作用。
    我们以单槽模式简单说明：
    没有漏掉的话，在构式数据库中有三个单槽构式：“何+X+之+有”，“ 一+无+所+v”，“照+v+不误”（变项究竟是X还是具体的词性我没统一，常项究竟是按词分写还是合写我也没统一，不出错保持现状即可。）
    在搜狗词库的提取结果中，没有“何X之有”和“照X不误”。这是我讨论的能产性的重点之一：可见的能产性不是真正的能产性。因此，无法通过词库、甚至语料库，以聚类的形式找到全部的结构。
    在搜狗词库的提取结果中，还有“无所不X”，“不知所X”等感觉上比较像构式的结构；如果标准放宽点，还有“目光如X（X=电、炬、豆、鼠、水……）”、“一代宗X（X=匠、工、臣、师……）”。这些结构的实例频率都很低，所以必须手工检视才能挑选出来；在成千上万个结构中挑选并非易事。
    另一方面，我们用一个词条数目最少的细胞成语词库（包含成语4203个）作为基准（我们感觉数目越少质量越高），在CCL现代汉语语料库和500万条微博语料库中分别进行单槽模式的甄选，算法如下：
        a.将每一个词拆为四个单槽模式，如将“一无所有”拆为“X无所有”、“一X所有”、“一无X有”和“一无所X”，这样理论上将得到4203 * 4 = 16812个单槽模式，实际上会少于这个数，因为会有多个词共享一个单槽模式（如一无所有、一无所获共享“一无所X”）；
        b. 去数据库中进行匹配词库之外的实例（如遇到“一无所有”实例时不统计，因为“一无所有”就是细胞词库中的词），其中X只能为单字。
    结果如下：
         CCL：匹配成功的单槽模式数量：11498；不同实例数（type数）：58217；总实例数（token数）：422723
         weibo：匹配成功的单槽模式数量：7989；不同实例数（type数）：27798；总实例数（token数）：149192
    这个结果水分很大，因为对于那些一位和四位上空缺的单槽模式，匹配到的结果很可能是错的，如（来自微博语料）：
    显然“进一步”是跟右边的成分结合的，而“海底捞”是一个火锅品牌，所以通过“海底捞月”“海底捞针”进行匹配得到的结果基本都不是有效结果。
    相对而言，二位和三位上空缺匹配到的实例准确度要高一些，不过也不是绝对的。二位和三位的单槽模式有多少呢？
        CCL：一位空缺：2915；四位空缺：2926；二位+三位空缺：11498 - 2915 - 2926 = 5657 = 2828.5 * 2
        weibo：一位空缺：2070；四位空缺：1922；二位+三位空缺：7989 - 2070 - 1922 = 3997 = 1998.5 * 2
    这个统计说明了什么呢？在真实语料中，一半以上的成语都会发生单槽模式化，形成新的临时用法。而我们很难说，这些临时用法会不会成为固定用法，而由模式化转变为构式化。更不用说有效地统计哪些是真实例、哪些是伪实例了。

    而在数据库中占有极大比例的交替双槽模式，其中有极大比例的是对举模式，对举模式中除了意义较虚的方位对举外，都是名、动、形的实词对举。这么一大类的对举模式，它们的能产性是很低的，因为它们的意义固定，限制了它们的创造性用法，如：
    它们最多也就4、5个实例，还经常分多种情况：兵来将挡是主谓，兵多将广是主表；龙争虎斗是主谓，龙潭虎穴是偏正。
    如果把这些都看作构式，那么现代汉语半凝固构式不说成千上万，成百上千是肯定有的：能够对举的实词实在是太多了。而在细胞词库的统计中，这些词实例数量参差不齐，很难用简单的方法挑选出来。

    我下次报告时会详细地进行讨论。大家对“量化构式数量”方面有什么建议，请不吝提出。
20160328
值得一提的是，我现在的一个观点是，虽然对举型四字格（双槽模式）看上去实例最多、形式最丰富，但能产性上远不如引喻型四字格（单槽模式），道理很简单，单槽模式的生产比双槽模式要省力（填一个槽 v.s. 填两个槽）；另一方面人类生产语言大多数是依赖经验而不是理性，人类不擅长理性地、显式地运用规则地生产语言，而单槽模式显然比双槽模式意义更具体，经验性更足。
20160317
 粗略浏览了一下各种文献，打算本学期两次报告如下：

    1. 汉语对举四字格研究综述：
    这篇报告主要等我对：a. CCL构式库里的半凝固构式; 和 b. 搜狗细胞词库提取出的“交替双槽模式”，进行整理后再阅读相关文献，以综述他们研究的长处和不足。预计整理工作在下周五前完成，阅读和综述工作在下下周周五前完成。可在宇晶做完毕业论文中期报告后进行报告。
    目前看到的前人研究的两点不足有：a. 绝大多数文章都只着眼于交替双槽模式，对于一四双槽模式（如“X而不Y”）和单槽模式（如“无所不X”）、三槽模式（如“XY而Z”）的关注度不大。b. 过于注重描写，而不注重生成；描写所构建的一大堆理论框架（包括对构式进行错误的、无谓的分类，将实例义、语境义赋予构式义，所有实例一视同仁，），很难应用到生成上，也增加了生成的负担，因而只能“描述”能产性，而无法“解释”能产性。
    对于第二点不足，还要慎重论述、具体论述，避免不必要的误会。
    目前找到的一些文献：
    构式语法视野下古汉语凝固结构研究_韩立秋
    现代汉语对举嵌置式四字格习得研究_王娇
    现代汉语_A_X_B_Y_对举格式考察_窦玉荣
    _红楼梦_待嵌格式研究_陈蔚舒

    此外还会找一些具体的比如方位词待嵌格式的研究进行综述。

    2. Design Methods for FCG
    这篇文献是Computational Issues in FCG Luc Steels的第一篇，也是一个介绍性的文章。通过这篇文章把曾经报告过的FCG串起来，形成一篇对FCG的总体性认知。重点报告其中的语言理论部分（第二章），比如我非常感兴趣的2.1节：The functionalist versus Formalist Perspective on Language。
    这份报告预计在所有实验（从语料库中发现新的四字结构）进行完后再进行，毕业论文中打算增加一章“Linguistic Discussion”，作为对前面工程性工作的总结和提升。但本文的重点（一开始应阐明）仍是工程性的工作。
20160315
我回顾了一下上次提交的中期报告，确实缺少一个能够贯穿全文的思路（研究目的）。我又整理了一下上学期所有的一些想法，觉得可以概括如下：

    计算机句法分析时会分词：对于“喜极而泣”，会处理成“ 喜极而泣 / l ”（但实际上用NLPIR分词得到的是“ 喜/v 极/d 而/cc 泣/vg ”），而对于“悲极而泣”，“怒极而泣”，则可能分析为 “ 悲/ag 极/ng 而/cc 泣/vg ”。
    这样的分词结果显然是不符合预期的：我们并没有感觉到“悲极而泣”是四个支离破碎的单位，而是一个完整的单位。
    那么问题来了：
    1. “悲极而泣”是不是一个词（假设“喜极而泣”是一个词）？
      答：是
    2. 既然是一个词，那该不该收进词库？
      答：不该——除非它的频率已经足够高了，在人脑中十分凝固了。否则人们在看到这个词时，一定会 联想到/激活 它的基式（“喜极而泣”），也就是说它不是一个具有独立形式和意义的词，而是另一个词的临时派生形式。而且这样的派生有很多。
    3. 既然不收进词库，那遇到这样的词怎么办？
      【研究目的】答：研究清楚这类词的派生规律，并用这些规律帮助识别它们。换言之，分词的时候不仅仅依赖词表匹配，还借助于派生规律。
    4. 有哪些派生规律？
      【研究方法】答：1. 替换（主要体现在单槽模式）；2. 对举（双槽模式）；3. 紧缩（三槽模式）。随着槽数增加，基式作用越来越小。
    5. 构式在其中起了什么作用？
      【研究手段】答：指导作用。构式方法在此弥补了短语文法在构词上的不足。

    基于使用的观点比基于规则的观点更具体，更具有覆盖力。规则的观点倾向于二分：是规则就是规则，不是规则就不是规则，规则一旦建立，就好像可以脱离实例而存在。它对于像“人怂志短”这样似是而非的规则的处理能力是比较弱的。而基于使用的观点则强调实例的作用，注重规则形成的过程：尽管“人…志短”只有两个实例，但我不否认它的存在。
    FCG的观点则认为重点不在于规则有多完备（即构式库有多少构式），而是规则不完备时如何补救（repair），这个补救其实就是“规则的规则”，我们在文中就通过对细胞词库的分析找到了几种补救规则（主要是替换、对举，紧缩已经没法“有效补救”了）。
    整篇文章的逻辑还是如最开始设计的那样，先通过词库“人工训练”出规则集，再将规则集应用到语料库中——具体说，是语料库中被分词程序切分成支离破碎的连续单字词的片段上。我们试图从这些片段中找出一些更完整的东西。与开始设想得不一致的地方是，开始我们希望找到的是具体的规则集（即构式），而现在我们更倾向于找到规则的规则。很多的构式其实能产性都不强，例如“X眉Y目”，“心X手Y”，因为常项是名词，限制了其派生能力；但这类“对举交替双槽模式”的数量很庞大，对举构式的能产性很强。

    关于讨论班报告，我其实倾向于读一些理论性质的文章，而不是应用性质的文章。前者其实更难读，但读完后可能收获更大一些。我也十分乐意去读一些应用性质的文章，比如可以分别挑几篇待嵌格式、四字格、网络新词的文章来读，综述并评述。这样应该也是不错的读书报告。

20160229
论文原初打算分两部分：词库部分，也就是通过聚类把构式找出来；语料库部分，也就是通过语料来衡量找出的构式的“强度”，或称为构式感。但是现在打算把方向改一改：重点放在词库上。
    聚类算法不难写，在开题的时候其实已经写好并将聚类结果展示出来了，但我在接下来的研究中钻了一下牛角尖：我很好奇也很反感，为什么所有的四字词库组合到一起会产生9万多条记录，且中间有大部分是“噪音”，也就是根本不该收进来的四字组合（这些组合有些词义很弱，有些根本就不是词，而是一个短语的一部分）。于是我做了很多额外的统计，最开始的希望是尽量把那些根本不该收进来的四字组合剔出去，留下来一个像模像样的词表，然后再在这个词表上进行聚类，得到一个满意的构式集。——其实如果一开始就去重点、逐条分析那些高频的“二字交替显现、二字交替隐含”的构式，说不定能按照原计划进行下去，虽然结果可能比较粗糙。
    在这些额外的统计、分析和思考中，看到了一些很有意思的、很实际的问题。比如“简繁转换”，我费了一番功夫，弄明白了为啥会有“説”和“說”两个汉字。在这个过程中，我逐渐发现，要界定一个未登录的四字组合是不是词，成语感强不强，本身就是一件困难的事儿，也是一件有意义的事儿。——我现在有一个想法，断定一个未登录的四字组合是词，只有两种情况：要么它（某一时期）的频率特别高，要么它与已有的某一个（类）词发生了某种联系。第一种我称之为创造，第二种我称之为推理。创造的词不是我关注的重点，它频率的特点已经很突出了。我关心的是推理得来的词，它之所以能被推理得来，正因为构式在起作用。
    所以我现在想做的一件事情，就是借助构式的手段，去分析一个新结构到底该不该被收进词库中。结果大致是这样：如果一个结构不符合上述两种情况，那就根本不该收进词库；如果它频率很高且并没有明显由某一构式实例化而来的迹象，那就应该被收进词库；如果它像是从某一构式实例化而来，那么我们得分析，它到底是不是“误写”，比如，是不是写错字了。如果不是误写，那么可以收进词库，更准确地，可以收进个人词库，然后决定要不要进一步收进系统词库。——构式在其中起指导性的作用，我们首先要用构式的方法将这个9万多词的大词库“瘦瘦身”，然后给出今后遇到新词的解决办法。我的新题目是《构式指导下的现代汉语四字词库的规模控制》，其意义不仅是判断一个新的四字结构是不是“词”，更给出了一个工程上收录词的标准，避免把一些显然不是词的片段或者是误写的词被收入词库。
    而可以发现，以上的思路跟FCG的思想是一致的。我目前读到并理解的FCG的核心思想并不是“如何用已有的构式库去分析语言结构”，而是“如何在构式库不够用的时候仍能正常工作”（来了一个新词，发生Repair，要么改正该词，要么收录该词，要么舍弃该词）。我希望再回味一遍FCG的目的并不是说我要真的借用FCG的程序去分析，而是我希望用他们的观点来加强我的论述。另外还有一个我认为很深刻的思想就是Preemption，这个已经比较清楚地报告过了。——我的论文其实最终的目的并不是提出一个精简词库的方法，而是论述一个词是怎么来的。最终是想解释，什么是构式。
    我在下周五的报告中会具体地展开一些问题。

